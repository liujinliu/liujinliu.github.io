---
title: 记一次docker部署web服务性能瓶颈解决过程
date: 2018-01-18
categories: 运维
---
在云计算领域，采用容器部署web服务越来越普遍，具有部署速度快，动态伸缩简单的特点。
最近参与了一次公司采用docker容器技术部署web服务的一次实践，在压测过程遇到了一个性能问题，记录下来作为以后开发的一个积累。
### 问题描述
#### 测试环境
单台物理机，24核，120G内存
#### 部署场景
采用docker容器，容器内部跑web应用。
#### 压测过程
并发500访问。
1.启动一个容器，进行压测 
2.启动四个容器，进行压测 
#### 问题现象
单容器场景下，没发现问题，跟物理部署单tomcat场景比，tps接近(均达到了17k)。 
四个容器的场景下，发现tps只到23k，并且cpu占用只在50%左右。
后来我们把容器数量加到6个，发现依然没有改善，tps并没有上升。cpu占用率也没有提升。

### 问题分析
这个场景下很显然是有资源在cpu之前先到达了瓶颈。从而导致即使增加容器实例部署，也无法使cpu利用率上升。但通过对内存，network-io，disk-io监控，都没有发现有瓶颈出现，并且看了tomcat的线程数，即使全达到最大，也不会超出物理机的线程数限制。而在另外一个物理机上，这个tomcat的配置，4个实例是几乎可以将cpu打满。
### 问题定位解决过程
因为单容器时候没发现问题，因此我们重点怀疑是物理机的配置导致的。因此在我们这个启动容器的物理机上也部署了4个tomcat实例，压测发现果然跟4个容器一样，cpu无法打满，tps上不去。
这时候开发人员给了一个提示，怀疑是有cpu的软中断处理不过来了。
于是在又一次的压测过程，采用下面的命令进行监控
```
mpstat -P ALL 1
```
果然发现有个别cpu一直处于忙碌当中(idel列一直为0)
于是开发怀疑是物理的RPS没开，后来设置RPS之后就好了。

### 关于RPS/RFS的一些理解
参考
http://blog.csdn.net/yy405145590/article/details/9837839
http://www.linuxidc.com/Linux/2015-07/119424.htm

- RPS全称是 Receive Packet Steering, 这是Google工程师 Tom Herbert (therbert@google.com )提交的内核补丁, 在2.6.35进入Linux内核. 这个patch采用软件模拟的方式，实现了多队列网卡所提供的功能，分散了在多CPU系统上数据接收时的负载, 把软中断分到各个CPU处理，而不需要硬件支持，大大提高了网络性能。
- RFS 全称是 Receive Flow Steering, 这也是Tom提交的内核补丁，它是用来配合RPS补丁使用的，是RPS补丁的扩展补丁，它把接收的数据包送达应用所在的CPU上，提高cache的命中率。
- 这两个补丁往往都是一起设置，来达到最好的优化效果, 主要是针对单队列网卡多CPU环境(多队列多重中断的网卡也可以使用该补丁的功能，但多队列多重中断网卡有更好的选择:SMP IRQ affinity)

#### 简单原理
RPS实现了数据流的hash归类，并把软中断的负载均衡分到各个cpu，实现了类似多队列网卡的功能。由于RPS只是单纯的把同一流的数据包分发给同一个CPU核来处理了，但是有可能出现这样的情况，即给该数据流分发的CPU核和执行处理该数据流的应用程序的CPU核不是同一个：数据包均衡到不同的cpu，这个时候如果应用程序所在的cpu和软中断处理的cpu不是同一个，此时对于cpu cache的影响会很大。那么RFS补丁就是用来确保应用程序处理的cpu跟软中断处理的cpu是同一个，这样就充分利用cpu的cache。

- 应用RPS之前: 所有数据流被分到某个CPU, 多CPU没有被合理利用， 造成瓶颈
- 应用RPS之后: 同一流的数据包被分到同个CPU核来处理，但可能出现cpu cache迁跃
- 应用RPS+RFS之后: 同一流的数据包被分到应用所在的CPU核

#### 必要条件
使用RPS和RFS功能，需要有大于等于2.6.35版本的Linux kernel
